# Java集合笔记

![](https://banxia-log.oss-cn-beijing.aliyuncs.com/Java%E5%85%AB%E8%82%A120260209014731365.png)

# 概述：

## 数组与集合的区别？

|   **特性**   |                      **数组 (Array)**                       |              **集合 (Collection/List)**              |
| :----------: | :---------------------------------------------------------: | :--------------------------------------------------: |
| **容量大小** |             **固定**。一旦创建，长度不可改变。              |        **动态**。可以根据需要自动扩容或缩减。        |
| **存储类型** | 既可以存**基本数据类型**（int, double），也可以存**对象**。 | 通常只能存**对象**（基本类型会被自动装箱为包装类）。 |
|   **性能**   |           **极高**。因为内存连续，访问速度最快。            |    **较高**。但由于有额外的管理开销，略逊于数组。    |
| **访问方式** |                        支持直接访问                         |                    通过迭代器访问                    |
| **功能扩展** |           功能单一，仅提供 `.length` 和索引访问。           |    **丰富**。提供排序、搜索、去重、各种算法接口。    |

## 说说集合？

集合框架分为两个体系：实现 Collection 接口的单列体系，实现 Map 的双列体系

**Collection：**作为单列集合的顶层接口，定义了增删改查等基础接口，同时，它继承了 **Iterable** 接口，所以也能使用迭代器进行遍历

- **List：**有序，有索引，可重复的集合，常用：ArrayList，LinkedList
  - **ArrayList：**容量可变，线程不安全，底层是数组，所以随机访问速度快，增删速度慢
  - **LinkedList：**容量可变，线程不安全，双向链表，所以增删快，随机访问慢
- **Set：**无序，不可重复，常用：HashSet，LinkedHashSet和TreeSet
  - **HashSet：**无序，唯一，高性能，线程不安全，通过 HashMap 实现，存储的值就是Map的Key，与之对应的V，就是一个名为 `PRESENT` 的 Object 对象
  - **LinkedHashSet：**有序，唯一，性能略低，线程不安全，通过 HashSet + LinkedList 实现，哈希表负责唯一性，双向链表负责有序性
  - **TreeSet：**排序，唯一，不允许NULL，通过 TreeMap 实现底层，保证排序，可以自定义规则

**Map：**作为双列集合的顶层接口，同样也定义了一些增删改查接口，Map的每一个条目包括K和V，K唯一，V不唯一

- **HashMap：**经典的Map，JAVA8之前使用数据+链表实现的，对于碰撞的情况使用链表存储，链表过长会影响查询速度，在JAVA8之后采用数组+链表+红黑树，当链表长度达到8之后就用红黑树处理碰撞情况，增加性能
- **LinkedHashMap：**HashMap + 双向链表，通过重写节点类，在原有的基础上增加before和after，增加了顺序存储的功能
- **TreeMap：**通过红黑树实现，可以对K进行排序
- **ConcurrentHashMap：**线程安全的高并发Map，不允许NULL，JAVA7采用分段锁提升性能，每一段数据单独枷锁，JAVA8采用CAS + synchronized，锁的粒度更小，空桶直接插入，有数据的锁住链表或者红黑树的两个头结点，如果两个线程没发生哈希冲突，就能完全并行

# List

# Map

## 说说 Java 中 HashMap 的原理

- 通过计算 Key 的 HashCode，然后用 `(table.length-1) & hash` 计算出 Value 应该在数组的什么位置，然后存放
- 如果发生哈希碰撞，就把哈希值相同的 Value 通过链表串起来，在 JDK8 之后做了优化，对于长度大于八的链表，且数组长度大于64，使其进化成红黑树，以增加性能，在红黑树节点小于6时，退化成链表
- 如果数组的使用率超过了负载因子，就会进行扩容，数组大小翻倍，然后数据进行迁移，称之为 rehash，性能开销较大

## Java 中 HashMap 的扩容机制是怎样的？

- 是否扩容主要有两个东西决定， 容量和负载因子，当使用率超过负载因子的时候，就会触发扩容，容量翻倍并且调整每个元素的位置，容量默认是16，负载因子默认是0.75
- 计算新位置的方法在1.8做了优化，数组的长度永远是二的N次方，根据公式：`(table.length-1) & hash` 我们发现，在扩容前后，`(table.length-1)`只有高位多了个1，我们只需要检查`hash`的这一位是否是1就可以快速判断是否移动就可以
- rehash 的性能开销大，为了平衡查询效率和 rehash 的性能开销，根据泊松分布分析，0.75是最优的解决方案
- 最好的方案就是指定初始的容量，大小为预计数据/0.75，需要注意，这个结果会靠近最近的2的幂次。1000为1024.

## 假设有一个 1G 大的 HashMap，此时用户请求过来刚好触发它的扩容，会怎样？让你改造下 HashMap 的实现该怎样优化？

- 1G 的 HashMap 显然很大，使用当前线程进行 rehash，就会进行阻塞，肯定不行
- Redis是单线程的，如果他遇到这种大规模 Map 扩容，肯定也有很好的解决方案：渐进式rehash。
  - 简而言之就是我们将原来一次性的扩容操作改成分批完成，在这个过程中，我们维护两个数组：
    - 原数组，包含未迁移的数据
    - 新数组：存储扩容后的数据
  - 实现过程就是我们创建好新数组时候，只搬运一点数据，然后记录下当前搬运进度，当有插入，修改，查询的操作时，继续迁移部分数据，直到完成迁移
  - 现在有两个数组，`get`操作会优先查找新数组，如果没有再去旧数组查找
- 除了 Redis，ConcurrentHashMap 的多线程渐进扩容也很优秀
  - 和 Redis 一样，ConcurrentHashMap 会创建另外一个二倍原数组大小的新数组用于存放迁移后的数据（nextTable），并且不会一次性迁移数据，其他线程可以参与这个迁移过程
  - ConcurrentHashMap 维护一个 transferIndex 用于记录当前迁移进度，从高位开始，逐步递减，每个线程都会抢占 transferIndex 的一段范围，执行迁移，如果某个桶的数据迁移完毕，就会将旧表中的引用替换为 ForwardingNode，指向 nextTable。
  - 全部迁移完毕之后，nextTable 会替换原数组，nextTable 变为NULL，至此，扩容完成

## ConcurrentHashMap 扩容期间，如果一个线程正在查询数据，会被阻塞吗?

很显然不会，ConcurrentHashMap 是异步进行扩容的，也就是说，扩容操作不会阻塞当前使用的线程，当前线程查询数据时，如果当前数据完成迁移，当前哈希桶就会读到 ForwardingNode，指向新表，就从新表读取数据了，不加锁，不阻塞

## 如果扩容期间，多个线程同时要迁移同一个桶，会冲突吗?

不会，根本不会出现多个线程枪一个桶的情况，因为 ConcurrentHashMap 通过 transferIndex 维护当前迁移进度，每个线程从这里领取桶范围，这个操作是原子性的，一个桶保证只会被一个线程迁移，不会冲突

## 渐进式 rehash 会不会导致内存占用翻倍?

会的，因为渐进式rehash 需要同时维护两个数组，需要消耗三倍的内存，这其实是一个空间换时间的解决方案，如果内存紧张，这个方案就不是这么适用了，可以考虑分片操作或者直接升级内存容量

## 如果在扩容期间，频繁进行 put 操作，会不会导致扩容一直完不成?

并不会

- 首先，put 操作会将数据放到新数组中， 不会出现哈希桶已经迁移完的情况下又进来新数据了
- 其次，put 操作会带动旧数据迁移，所以，put 的越快，迁移也越快
- 但是如果咔咔咔一直 put，原数组还没扩容完成，新数组就满了，那就是另外一回事了，我们要重新规划容量了

## 扩容的时候，链表和红黑树的处理方式一样吗？

不一样

- 链表在被迁移的时候会通过 HashCode的高位情况，分裂成两个链表，高位为1的移动到原下标+旧数组长度的位置，高位为0的保持不变
- 红黑树也是进行这样的操作，分成两个红黑树，但是分完要进行检查，如果节点小于6个，就要进行退化

## HashMap 扩容时线程安全吗？

不安全，如果两个线程同时进行扩容操作，就会导致链表成环，get 的时候就会一直循环，爆炸了，1.8改用尾插法解决了这个问题，但是put 的时候还是会丢数据，数据被覆盖，所以，使用 ConcurrentHashMap 更加安全

## 能不能让 HashMap 不扩容？

当然可以，直接让负载因子非常大，就不会扩容，但是这种方法显然不合适，以为内如果一直不扩容，就会一直发生碰撞，单个桶下的数据急剧增多，查找效率急剧下降，即使有红黑树兜底，频繁树化效率也是惨不忍睹，还是应该预估一下数据的数量，设置好初始容量

## Java 中的 hashCode 和 equals 方法之间有什么关系？ 

equals 相等的对象，hashCode 必须相等；hashCode 相等的对象，equals 不一定相等

 这个有什么用呢，如果我们需要更改一个对象的 equals 方法，同时这个对象也要被放到 HashMap 或者 HashSet中，那么也要重写 hashCode 方法，因为 HashMap 和 HashSet 在判断是否相等的时候会优先调用 hashCode 方法，如果没有重写 hashCode 方法，这一关过不去，其也不会去调用 equals 方法，集合的单一性就不能保证了

## 两个对象 hashCode 相同但 equals 不相等，这种情况叫什么？会影响 HashMap 性能吗？

典型的哈希冲突，如果发生这种情况，HashMap 会将这两个对象以链表的形式组织到一个槽里面，如果之后还发生了碰撞，就加长链表，JDK8 之后，如果链表长度大于8就使用红黑树代替链表，优化查询速度

## String 类的 hashCode 是怎么算的？为什么这么设计？

Java 中 String 类的 hashCode 计算方式是一个基于 31 的多项式累加算法，具体来说：h = 31 * h + c，计算完毕之后就进行缓存，因为String不可变，之后直接返回就行。选择 31 作为乘数是因为他是奇质数，计算出来的哈希值比较均匀，而且31正好是32-1，可以被JVM优化为位移和减法，计算效率更高

## HashMap 的 key 用可变对象有什么风险？

很简单，如果使用可变对象作为K的话，一旦这个我们更改这个Key，HashCode 也会不一样，我们拿着新的 HashCode 去找，肯定找不到，原来的数据也删不掉，就这样造成了内存泄漏，极其不安全

## 重写 equals 不重写 hashCode，除了集合出问题，还有什么影响？

基本不会有问题，但是保不齐那天突然要放到里面，还有就是不是我们想放到里面，有些框架需要将具体对象放到集合中进行维护，而那时候又忘了重写，给自己埋雷了属于是

## 为什么 JDK 1.8 对 HashMap 进行了红黑树的改动？ 

- 在1.8之前，对于哈希碰撞的处理一般是将这些发生碰撞的对象组织到一条链表进行管理，查询的时候挨个进行比对，效率低下，如果有人故意存入大量互相碰撞的对象，然后查询，就会直接卡死，当当，这就是哈希碰撞攻击
- 1.8采用树化的机制来应对这种问题，简单来说就是当链表的长度大于8且数组长度大于64的时候，就进行树化操作，链表转化为红黑树，查询效率从 O(n) 变为 O(log n)。如果节点数目变为6以下，再次退化成链表
- 使用8和6为界限判断是为了防止这些发生碰撞的数据从链表和红黑树之间反复横跳带来的性能开销

## 什么是 Hash 碰撞？怎么解决哈希碰撞？ 

# List

# Set
